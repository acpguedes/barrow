Metadata-Version: 2.4
Name: barrow
Version: 0.1.0
Summary: A Bash tool for data manipulation using tabular formats, based on Apache Arrow.
Author: Barrow Developers
License: MIT License
        
        Copyright (c) 2024 Barrow Developers
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pyarrow
Requires-Dist: numpy
Requires-Dist: duckdb
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Requires-Dist: argcomplete; extra == "dev"
Requires-Dist: commitizen; extra == "dev"
Provides-Extra: docs
Requires-Dist: mkdocs>=1.5; extra == "docs"
Requires-Dist: mkdocs-material; extra == "docs"
Dynamic: license-file

# barrow
A Bash tool for data manipulation using tabular formats, based on Apache Arrow.
It supports common data operations like select, filter, mutate, groupby, summary, ungroup, and join.
Commands read from files or `STDIN` and write to files or `STDOUT` in CSV or Parquet format.

## Installation
```bash
pip install barrow
```

For a development install with linting and testing tools:

```bash
make install
```

`make install` installs development dependencies and configures pre-commit hooks.

To create an isolated environment with autocompletion, run:
```bash
source scripts/setup_env.sh
```
A minimal Dockerfile is available for container usage:
```bash
docker build -t barrow .
docker run --rm barrow --help
```

The Makefile also provides common tasks:

```bash
make lint    # run linters via pre-commit
make format  # format code via pre-commit
make test    # run the test suite
make clean   # remove build artifacts
```

## Usage
All subcommands accept `--input`/`-i`, `--input-format`, `--output`/`-o`, and `--output-format` to control I/O. These options support `csv` or `parquet`. When omitted, formats are inferred from file extensions or magic bytes when reading from `STDIN`. Leaving out `--input` makes the command read from `STDIN`; omitting `--output` writes to `STDOUT`. If `--output-format` is not given, the command writes using the input format.

### filter
`barrow filter EXPRESSION`
: Filter rows by a boolean expression.

### select
`barrow select COLUMN[,COLUMN...]`
: Select specific columns.

### mutate
`barrow mutate NAME=EXPR[,NAME=EXPR...]`
: Add or modify columns using expressions.

### groupby
`barrow groupby COLUMN[,COLUMN...]`
: Group rows by one or more columns.

### summary
`barrow summary COLUMN=AGG[,COLUMN=AGG...]`
: Aggregate a grouped table using functions like `sum`, `mean`, or `count`.

### ungroup
`barrow ungroup`
: Remove grouping metadata from a table.

### join
`barrow join LEFT_KEY RIGHT_KEY --right FILE [--join-type TYPE]`
: Join two tables. `--join-type` accepts `inner`, `left`, `right`, or `outer`; `--right-format` chooses the right table's format.

## Examples
### Filter then select
```bash
# filter outputs CSV by default; select converts to Parquet
barrow filter "a > 1" --input data.csv --input-format csv | \
barrow select "b,grp" --output-format parquet --output result.parquet
```

### Mutate → groupby → summary
```bash
# mutate and groupby inherit CSV; summary converts to Parquet
barrow mutate "c=a+b" --input data.csv --input-format csv | \
barrow groupby grp | \
barrow summary "c=sum" --output-format parquet --output out.parquet
```

### Filter → mutate → select → groupby → summary
```bash
# filter, mutate, select, groupby, and summarize
barrow filter "a > 1" --input data.csv --input-format csv | \
barrow mutate "c=a+b" | \
barrow select "c,grp" | \
barrow groupby grp | \
barrow summary "c=sum"
```

```csv
grp,c_sum
x,7
y,9
```

Note: Writing grouped data to CSV drops grouping metadata; use Parquet to preserve it.

These pipelines demonstrate reading from `STDIN` and writing to `STDOUT` while combining operations with pipes.

## Roadmap
- Support window functions
- Provide a SQL interface

## Testing
Run the test suite with:

```bash
make test
```

Optional dependencies:
- `argcomplete` for shell auto-completion (`pip install argcomplete`).
